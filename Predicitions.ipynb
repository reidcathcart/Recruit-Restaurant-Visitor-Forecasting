{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import some useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:19:49.152758Z",
     "start_time": "2018-09-24T05:19:46.122497Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from sklearn import ensemble,model_selection,preprocessing,feature_selection,metrics\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the files as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:19:54.203850Z",
     "start_time": "2018-09-24T05:19:49.153757Z"
    }
   },
   "outputs": [],
   "source": [
    "df_air_reserve = pd.read_csv('air_reserve.csv.zip')\n",
    "df_air_store = pd.read_csv('air_store_info.csv.zip')\n",
    "df_air_visit = pd.read_csv('air_visit_data.csv.zip')\n",
    "df_hpg_reserve = pd.read_csv('hpg_reserve.csv.zip')\n",
    "df_hpg_store = pd.read_csv('hpg_store_info.csv.zip')\n",
    "df_date_info = pd.read_csv('date_info.csv.zip')\n",
    "df_store_id_rel = pd.read_csv('store_id_relation.csv.zip')\n",
    "df_sample = pd.read_csv('sample_submission.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some constants for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:19:54.307778Z",
     "start_time": "2018-09-24T05:19:54.211838Z"
    }
   },
   "outputs": [],
   "source": [
    "# map months to seasons\n",
    "seasons = {'Jan': 'Winter','Feb': 'Winter','Mar': 'Spring','Apr': 'Spring','May': 'Spring','Jun': 'Summer',\n",
    "           'Jul': 'Summer','Aug': 'Summer','Sep': 'Autumn','Oct': 'Autumn','Nov': 'Autumn','Dec': 'Winter'}\n",
    "\n",
    "# roll up genres\n",
    "genres = {\n",
    "    'Japanese style':'Japanese',\n",
    "    'International cuisine':'Other',\n",
    "    'Grilled meat':'Other Asian',\n",
    "    'Creation':'Japanese',\n",
    "    'Italian':'European',\n",
    "    'Seafood':'Other',\n",
    "    'Spain Bar/Italian Bar':'European',\n",
    "    'Japanese food in general':'Japanese',\n",
    "    'Shabu-shabu/Sukiyaki':'Japanese',\n",
    "    'Chinese general':'Other Asian',\n",
    "    'Creative Japanese food':'Japanese',\n",
    "    'Japanese cuisine/Kaiseki':'Japanese',\n",
    "    'Korean cuisine':'Other Asian',\n",
    "    'Okonomiyaki/Monja/Teppanyaki':'Japanese',\n",
    "    'Karaoke':'Bar or Club',\n",
    "    'Steak/Hamburger/Curry':'Other',\n",
    "    'French':'European',\n",
    "    'Cafe':'European',\n",
    "    'Bistro':'Other',\n",
    "    'Sushi':'Japanese',\n",
    "    'Party':'Bar or Club',\n",
    "    'Western food':'Other',\n",
    "    'Pasta/Pizza':'Other',\n",
    "    'Thai/Vietnamese food':'Other Asian',\n",
    "    'Bar/Cocktail':'Bar or Club',\n",
    "    'Amusement bar':'Bar or Club',\n",
    "    'Cantonese food':'Other Asian',\n",
    "    'Dim Sum/Dumplings':'Other Asian',\n",
    "    'Sichuan food':'Other Asian',\n",
    "    'Sweets':'Other',\n",
    "    'Spain/Mediterranean cuisine':'European',\n",
    "    'Udon/Soba':'Japanese',\n",
    "    'Shanghai food':'Other Asian',\n",
    "    'Taiwanese/Hong Kong cuisine':'Other Asian',\n",
    "    'Japanese food':'Japanese', \n",
    "    'Dining bar':'Bar or Club', \n",
    "    'Izakaya':'Japanese',\n",
    "    'Okonomiyaki/Monja/Teppanyaki':'Japanese', \n",
    "    'Italian/French':'European', \n",
    "    'Cafe/Sweets':'Other',\n",
    "    'Yakiniku/Korean food':'Other Asian', \n",
    "    'Western food':'Other', \n",
    "    'Bar/Cocktail':'Bar or Club', \n",
    "    'Other':'Other',\n",
    "    'Creative cuisine':'Japanese', \n",
    "    'Karaoke/Party':'Bar or Club', \n",
    "    'International cuisine':'Other',\n",
    "    'Asian':'Other Asian',\n",
    "    'None':'None',\n",
    "    'No Data':'No Data'}\n",
    "\n",
    "# function to aggregate various values to add as features. Tables will be added to a dictionary\n",
    "def groupings(df,group,field,agg,name,cols):\n",
    "    for i in group:\n",
    "        tmp = df.groupby([i])\\\n",
    "                .agg(agg)\n",
    "        tmp.columns = tmp.columns.map(''.join)\n",
    "        tmp.columns=[s + i for s in cols]\n",
    "        tmp.reset_index(inplace=True)\n",
    "        name[i]=tmp\n",
    "        name[i].columns = name[i].columns.map(''.join)\n",
    "        for j in field:\n",
    "            tmp = df.groupby([i,j])\\\n",
    "                    .agg(agg)\n",
    "            tmp.columns = tmp.columns.map(''.join)\n",
    "            tmp.columns=[s + i+j for s in cols]\n",
    "            tmp.reset_index(inplace=True)\n",
    "            name[i+j] = tmp\n",
    "            \n",
    "# for the CV\n",
    "splits=4\n",
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "\n",
    "# calculate error\n",
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangle the reservation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:19:54.512672Z",
     "start_time": "2018-09-24T05:19:54.312774Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge 'air' tables and bring over any 'hpg' store data\n",
    "df_air_merged = df_air_reserve.merge(df_air_store,on='air_store_id', how='left').merge(\n",
    "    df_store_id_rel, on='air_store_id', how='left').merge(df_hpg_store,on='hpg_store_id', how='left',suffixes=('_air','_hpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:19:58.657267Z",
     "start_time": "2018-09-24T05:19:54.516668Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge 'hpg' tables and bring over any 'air' store data\n",
    "df_hpg_merged = df_hpg_reserve.merge(df_hpg_store,on='hpg_store_id', how='left').merge(\n",
    "    df_store_id_rel,on='hpg_store_id', how='left').merge(df_air_store,on='air_store_id', how='left',suffixes=('_hpg','_air'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:19:58.678256Z",
     "start_time": "2018-09-24T05:19:58.659267Z"
    }
   },
   "outputs": [],
   "source": [
    "# add source column\n",
    "df_air_merged['source'] = 'air'\n",
    "df_hpg_merged['source'] = 'hpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:19:59.629719Z",
     "start_time": "2018-09-24T05:19:58.680256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# append tables together\n",
    "df_res_merged = df_air_merged.append(df_hpg_merged, sort=True)\n",
    "df_res_merged.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:20:08.304720Z",
     "start_time": "2018-09-24T05:19:59.634705Z"
    }
   },
   "outputs": [],
   "source": [
    "# format date fields\n",
    "df_res_merged['visit_datetime'] = pd.to_datetime(df_res_merged.visit_datetime)\n",
    "df_res_merged['reserve_datetime'] = pd.to_datetime(df_res_merged.reserve_datetime)\n",
    "\n",
    "df_res_merged['calendar_date'] = df_res_merged.visit_datetime.dt.date\n",
    "df_res_merged['visit_time'] = df_res_merged.visit_datetime.dt.time\n",
    "df_res_merged['reserve_date'] = df_res_merged.reserve_datetime.dt.date\n",
    "df_res_merged['reserve_time'] = df_res_merged.reserve_datetime.dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:22:38.894638Z",
     "start_time": "2018-09-24T05:20:08.311707Z"
    }
   },
   "outputs": [],
   "source": [
    "# add month, year, and season\n",
    "df_res_merged['visit_month'] = df_res_merged.visit_datetime.apply(lambda x: x.strftime(\"%b\"))\n",
    "df_res_merged['visit_year'] = df_res_merged.visit_datetime.apply(lambda x: x.strftime(\"%Y\"))\n",
    "df_res_merged['reserve_month'] = df_res_merged.reserve_datetime.apply(lambda x: x.strftime(\"%b\"))\n",
    "df_res_merged['reserve_year'] = df_res_merged.reserve_datetime.apply(lambda x: x.strftime(\"%Y\"))\n",
    "\n",
    "df_res_merged['reserve_season'] = df_res_merged['reserve_month'].map(seasons)\n",
    "df_res_merged['visit_season'] = df_res_merged['visit_month'].map(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:22:52.020066Z",
     "start_time": "2018-09-24T05:22:38.897626Z"
    }
   },
   "outputs": [],
   "source": [
    "# format df_date_info date to merge\n",
    "df_date_info['calendar_date'] = pd.to_datetime(df_date_info.calendar_date)\n",
    "df_date_info['calendar_date'] = df_date_info.calendar_date.dt.date\n",
    "df_res_merged = df_res_merged.merge(df_date_info, on='calendar_date', how='left')\n",
    "df_res_merged.rename(columns={\"day_of_week\": \"day_of_week_visit\", \"holiday_flg\": \"holiday_flag_visit\"}, inplace=True)\n",
    "df_res_merged = df_res_merged.merge(df_date_info, left_on='reserve_date', right_on='calendar_date', how='left')\n",
    "df_res_merged.rename(columns={\"day_of_week\": \"day_of_week_res\", \"holiday_flg\": \"holiday_flag_res\",\"calendar_date_x\": \"visit_date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:22:52.161986Z",
     "start_time": "2018-09-24T05:22:52.021058Z"
    }
   },
   "outputs": [],
   "source": [
    "# time between reservation and visit\n",
    "df_res_merged['res_vs_visit'] = df_res_merged['visit_datetime'] - df_res_merged['reserve_datetime']\n",
    "df_res_merged['res_vs_visit_days'] = df_res_merged['res_vs_visit'].astype('timedelta64[D]')\n",
    "df_res_merged['res_vs_visit_hours'] = df_res_merged['res_vs_visit'].astype('timedelta64[h]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:22:52.236939Z",
     "start_time": "2018-09-24T05:22:52.162986Z"
    }
   },
   "outputs": [],
   "source": [
    "# holiday the day before and after visit\n",
    "df_res_merged['holiday_before_visit'] = df_res_merged.holiday_flag_visit.shift(1)\n",
    "df_res_merged.holiday_before_visit.fillna(0,inplace=True)\n",
    "df_res_merged['holiday_after_visit'] = df_res_merged.holiday_flag_visit.shift(-1)\n",
    "df_res_merged.holiday_after_visit.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:22:59.612678Z",
     "start_time": "2018-09-24T05:22:52.240942Z"
    }
   },
   "outputs": [],
   "source": [
    "# too many genres - amalgamate\n",
    "\n",
    "df_res_merged.hpg_genre_name.fillna('No Data', inplace=True)\n",
    "df_res_merged.air_genre_name.fillna('No Data', inplace=True)\n",
    "df_res_merged.hpg_store_id.fillna('No Data', inplace=True)\n",
    "df_res_merged.air_store_id.fillna('No Data', inplace=True)\n",
    "df_res_merged.hpg_area_name.fillna('No Data', inplace=True)\n",
    "df_res_merged.air_area_name.fillna('No Data', inplace=True)\n",
    "df_res_merged['air_genre_amal'] = df_res_merged['air_genre_name'].map(genres)\n",
    "df_res_merged['hpg_genre_amal'] = df_res_merged['hpg_genre_name'].map(genres)\n",
    "\n",
    "# amalgamated genre - take air genre first then hpg\n",
    "df_res_merged['genre_amal']=df_res_merged['air_genre_amal']\n",
    "df_res_merged.loc[df_res_merged['air_genre_amal']=='No Data',['genre_amal']] = df_res_merged['hpg_genre_amal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:02.798850Z",
     "start_time": "2018-09-24T05:22:59.614678Z"
    }
   },
   "outputs": [],
   "source": [
    "# original genre - take air genre first then hpg\n",
    "df_res_merged['genre_2']=df_res_merged['air_genre_name']\n",
    "df_res_merged.loc[df_res_merged['air_genre_name']=='No Data',['genre_2']] = df_res_merged['hpg_genre_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:06.413766Z",
     "start_time": "2018-09-24T05:23:02.800840Z"
    }
   },
   "outputs": [],
   "source": [
    "# area - take air first then hpg\n",
    "df_res_merged['area_2']=df_res_merged['air_area_name']\n",
    "df_res_merged.loc[df_res_merged['air_area_name']=='No Data',['area_2']] = df_res_merged['hpg_area_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:17.357456Z",
     "start_time": "2018-09-24T05:23:06.415765Z"
    }
   },
   "outputs": [],
   "source": [
    "# get prefecture from area\n",
    "df_res_merged['area_2_pref'] = df_res_merged.area_2.apply(lambda x: x.split(' ')[0] if pd.notnull(x) else x)\n",
    "df_res_merged.loc[(df_res_merged['area_2_pref']=='No') | (df_res_merged['area_2_pref']=='None'),['area_2_pref']] = 'No Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangle the train/test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:17.407431Z",
     "start_time": "2018-09-24T05:23:17.358455Z"
    }
   },
   "outputs": [],
   "source": [
    "# prep sample submission df\n",
    "df_sample['visit_date'] = df_sample['id'].map(lambda x: str(x).split('_')[2])\n",
    "df_sample['air_store_id'] = df_sample['id'].map(lambda x: '_'.join(x.split('_')[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:17.438399Z",
     "start_time": "2018-09-24T05:23:17.409416Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "# append visit and sample file to consistently format features\n",
    "df_features=df_air_visit.append(df_sample, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:24.767196Z",
     "start_time": "2018-09-24T05:23:17.439399Z"
    }
   },
   "outputs": [],
   "source": [
    "# format df_date_info and add month, year, and season\n",
    "\n",
    "df_features['visit_date'] = pd.to_datetime(df_features.visit_date)\n",
    "df_features['visit_date'] = df_features.visit_date.dt.date\n",
    "df_features = df_features.merge(df_date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "df_features.drop('calendar_date', axis=1, inplace=True)\n",
    "df_features = df_features.merge(df_air_store,on='air_store_id', how='left')\n",
    "df_features['visit_month'] = df_features.visit_date.apply(lambda x: x.strftime(\"%b\"))\n",
    "df_features['visit_year'] = df_features.visit_date.apply(lambda x: x.strftime(\"%Y\"))\n",
    "df_features['visit_season'] = df_features['visit_month'].map(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:24.990068Z",
     "start_time": "2018-09-24T05:23:24.773175Z"
    }
   },
   "outputs": [],
   "source": [
    "# amalgamate genres like in reservations\n",
    "df_features.air_genre_name.fillna('No Data', inplace=True)\n",
    "df_features['air_genre_2'] = df_features['air_genre_name'].map(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:25.048023Z",
     "start_time": "2018-09-24T05:23:24.997047Z"
    }
   },
   "outputs": [],
   "source": [
    "# holiday the day before and after visit\n",
    "df_features['holiday_before_visit'] = df_features.holiday_flg.shift(1)\n",
    "df_features.holiday_before_visit.fillna(0,inplace=True)\n",
    "df_features['holiday_after_visit'] = df_features.holiday_flg.shift(-1)\n",
    "df_features.holiday_after_visit.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:25.991467Z",
     "start_time": "2018-09-24T05:23:25.053009Z"
    }
   },
   "outputs": [],
   "source": [
    "# prefecture from area\n",
    "df_features['area_pref'] = df_features.air_area_name.apply(lambda x: x.split(' ')[0] if pd.notnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:27.740482Z",
     "start_time": "2018-09-24T05:23:25.998467Z"
    }
   },
   "outputs": [],
   "source": [
    "# add golden week\n",
    "df_features['golden_week'] = df_features.visit_date.apply(lambda x: 1 if \n",
    "                            ((x>=(datetime.date(2016,4,29))) & (x<=(datetime.date(2016,5,7)))) |\n",
    "                            ((x>=(datetime.date(2017,4,29))) & (x<=(datetime.date(2017,5,7))))\n",
    "                                                                        else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:28.994745Z",
     "start_time": "2018-09-24T05:23:27.748463Z"
    }
   },
   "outputs": [],
   "source": [
    "# fix outliers - they dont appear to be an organic spike in visitors\n",
    "df_features.loc[df_features.visitors>250,['visitors']]= df_features.visitors//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:29.984165Z",
     "start_time": "2018-09-24T05:23:28.997734Z"
    }
   },
   "outputs": [],
   "source": [
    "df_features['weekday'] = df_features.visit_date.apply(lambda x: x.weekday())\n",
    "df_features['month'] = df_features.visit_date.apply(lambda x: x.month)\n",
    "df_features['weekend'] = df_features.weekday.apply(lambda x: 1 if x>=5 else 0)\n",
    "df_features['visit_year'] = df_features.visit_year.astype(int)\n",
    "df_features['holiday_flg'] = df_features.holiday_flg.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:31.751144Z",
     "start_time": "2018-09-24T05:23:29.988163Z"
    }
   },
   "outputs": [],
   "source": [
    "# copy original air_visit back to df_air_visit dataframe before calcuating aggregations\n",
    "df_air_visit = df_features[df_features.id.isna()].copy()\n",
    "\n",
    "# only include entries after 01 Jul 2016 as this is when we observe a significant and consistent uptick in values\n",
    "date_incl = datetime.date(2016,7,1)\n",
    "df_air_visit_incl = df_air_visit[(df_air_visit.visit_date)>=(date_incl)]\n",
    "df_res_merged_incl = df_res_merged[(df_res_merged.visit_date)>=(date_incl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:36.156628Z",
     "start_time": "2018-09-24T05:23:31.752144Z"
    }
   },
   "outputs": [],
   "source": [
    "# aggregate df_air_visit dataframe\n",
    "grp=['air_store_id','air_genre_2','air_genre_name','air_area_name','area_pref']\n",
    "fld=['visit_month','visit_season','day_of_week','holiday_flg','holiday_before_visit','holiday_after_visit','golden_week','weekend']\n",
    "aggr={'visitors':['mean','min','max','size']}\n",
    "col=['v_mean_','v_min_','v_max_','v_cnt']\n",
    "df_air_visit_grp={}\n",
    "groupings(df_air_visit_incl,grp,fld,aggr,df_air_visit_grp,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:56.230030Z",
     "start_time": "2018-09-24T05:23:36.162615Z"
    }
   },
   "outputs": [],
   "source": [
    "# aggregate df_res_merged dataframe\n",
    "grp=['genre_amal','genre_2','air_store_id','area_2_pref','area_2']\n",
    "fld=['visit_month','visit_season','day_of_week_visit','holiday_flag_visit','holiday_before_visit','holiday_after_visit','visit_date']\n",
    "aggr={'res_vs_visit_hours':'mean','reserve_visitors':'size'}\n",
    "col=['rvvh_','rvs_']\n",
    "df_res_merged_grp={}\n",
    "groupings(df_res_merged_incl,grp,fld,aggr,df_res_merged_grp,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:23:58.710016Z",
     "start_time": "2018-09-24T05:23:56.232027Z"
    }
   },
   "outputs": [],
   "source": [
    "# add selected aggregates to features df and scale them\n",
    "vis_grps = ['air_store_id', 'air_store_idvisit_month','air_store_idday_of_week', \n",
    "            'air_store_idholiday_flg','air_store_idholiday_after_visit',\n",
    "            'area_prefday_of_week', 'air_genre_name', 'air_area_name',]\n",
    "\n",
    "res_grps = ['air_store_id']\n",
    "\n",
    "for i in df_air_visit_grp:\n",
    "    if i in vis_grps:\n",
    "        #scaler = preprocessing.RobustScaler()\n",
    "        tmp = df_air_visit_grp[i]\n",
    "        #cols = [col for col in tmp if col.startswith('v_')]\n",
    "        #tmp[cols] = scaler.fit_transform(tmp[cols])\n",
    "        df_features = df_features.merge(tmp,how='left')\n",
    "        \n",
    "for i in df_res_merged_grp:\n",
    "    if i in res_grps:\n",
    "        #scaler = preprocessing.RobustScaler()\n",
    "        tmp = df_res_merged_grp[i]\n",
    "        #cols = [col for col in tmp if col.startswith('rv')]\n",
    "        #tmp[cols] = scaler.fit_transform(tmp[cols])\n",
    "        df_features = df_features.merge(tmp,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:24:02.162043Z",
     "start_time": "2018-09-24T05:23:58.712005Z"
    }
   },
   "outputs": [],
   "source": [
    "df_features['visit_date_int'] = df_features.visit_date.apply(\n",
    "    lambda x: x.strftime('%Y%m%d')).astype(int)\n",
    "# Instance of day of the week in the month eg/ 2nd Monday etc\n",
    "a = df_features.groupby(\n",
    "    ['visit_year', 'visit_month', 'day_of_week',\n",
    "     'visit_date_int'])['visit_date'].nunique().reset_index()\n",
    "a['x'] = a.groupby(['visit_year', 'visit_month',\n",
    "                    'day_of_week'])['visit_date'].cumsum()\n",
    "a.set_index('visit_date_int', inplace=True)\n",
    "df_features['visit_dow_cnt_month'] = df_features.visit_date_int.map(a['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:24:03.939990Z",
     "start_time": "2018-09-24T05:24:02.169026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rank of store in area per day of week\n",
    "a = df_air_visit_incl.groupby(\n",
    "    ['air_area_name', 'day_of_week',\n",
    "     'air_store_id'])['visitors'].sum().reset_index()\n",
    "a.sort_values(by=['air_area_name', 'day_of_week', 'visitors'], inplace=True)\n",
    "a['store_rank_area_dow'] = a.groupby(['air_area_name', 'day_of_week'\n",
    "                                      ])['air_store_id'].cumcount() + 1\n",
    "df_features = df_features.merge(\n",
    "    a[['air_store_id', 'day_of_week', 'store_rank_area_dow']],\n",
    "    how='left',\n",
    "    on=['air_store_id', 'day_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:24:04.253810Z",
     "start_time": "2018-09-24T05:24:03.941989Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rank of store in pref per day of week\n",
    "a = df_air_visit_incl.groupby(\n",
    "    ['area_pref', 'day_of_week',\n",
    "     'air_store_id'])['visitors'].sum().reset_index()\n",
    "a.sort_values(by=['area_pref', 'day_of_week', 'visitors'], inplace=True)\n",
    "a['store_rank_pref_dow'] = a.groupby(['area_pref', 'day_of_week'\n",
    "                                      ])['air_store_id'].cumcount() + 1\n",
    "df_features = df_features.merge(\n",
    "    a[['air_store_id', 'day_of_week', 'store_rank_pref_dow']],\n",
    "    how='left',\n",
    "    on=['air_store_id', 'day_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:24:04.544641Z",
     "start_time": "2018-09-24T05:24:04.255809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rank of store in area\n",
    "a = df_air_visit_incl.groupby(\n",
    "    ['air_area_name', 'air_store_id'])['visitors'].sum().reset_index()\n",
    "a.sort_values(by=['air_area_name', 'visitors'], inplace=True)\n",
    "a['store_rank_area'] = a.groupby(['air_area_name'\n",
    "                                  ])['air_store_id'].cumcount() + 1\n",
    "df_features = df_features.merge(\n",
    "    a[['air_store_id', 'store_rank_area']], how='left', on=['air_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:24:04.896443Z",
     "start_time": "2018-09-24T05:24:04.546641Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rank of store in area per genre\n",
    "a = df_air_visit_incl.groupby(\n",
    "    ['air_area_name', 'air_genre_name',\n",
    "     'air_store_id'])['visitors'].sum().reset_index()\n",
    "a.sort_values(by=['air_area_name', 'air_genre_name', 'visitors'], inplace=True)\n",
    "a['store_rank_area_genre'] = a.groupby(['air_area_name', 'air_genre_name'\n",
    "                                        ])['air_store_id'].cumcount() + 1\n",
    "df_features = df_features.merge(\n",
    "    a[['air_store_id', 'air_genre_name', 'store_rank_area_genre']],\n",
    "    how='left',\n",
    "    on=['air_store_id', 'air_genre_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:24:05.215264Z",
     "start_time": "2018-09-24T05:24:04.898438Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rank of store in pref per genre\n",
    "a = df_air_visit_incl.groupby(\n",
    "    ['area_pref', 'air_genre_name',\n",
    "     'air_store_id'])['visitors'].sum().reset_index()\n",
    "a.sort_values(by=['area_pref', 'air_genre_name', 'visitors'], inplace=True)\n",
    "a['store_rank_pref_genre'] = a.groupby(['area_pref', 'air_genre_name'\n",
    "                                        ])['air_store_id'].cumcount() + 1\n",
    "df_features = df_features.merge(\n",
    "    a[['air_store_id', 'air_genre_name', 'store_rank_pref_genre']],\n",
    "    how='left',\n",
    "    on=['air_store_id', 'air_genre_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:24:05.264237Z",
     "start_time": "2018-09-24T05:24:05.216264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature interactions\n",
    "df_features['lat_plus_long'] = df_features.latitude + df_features.longitude\n",
    "df_features['lat_sub_max'] = df_features.latitude.max() - df_features.latitude\n",
    "df_features['long_sub_max'] = df_features.longitude.max() - df_features.longitude\n",
    "df_features['meanvis_sub_max'] = df_features.v_mean_air_store_id.max() - df_features.v_mean_air_store_id\n",
    "df_features['meanres_sub_max'] = df_features.rvs_air_store_id.max() - df_features.rvs_air_store_id\n",
    "df_features['meanvisdow_mul_cnt'] = df_features.v_cntair_store_idday_of_week * df_features.v_mean_air_store_idday_of_week\n",
    "df_features['meanvis_mul_cnt'] = df_features.v_cntair_store_id * df_features.v_mean_air_store_id\n",
    "df_features['meanresh_mul_cnt'] = df_features.rvvh_air_store_id * df_features.rvs_air_store_id\n",
    "df_features['visit_date_int_mul_mean'] = df_features.visit_date_int * df_features.v_mean_air_store_id\n",
    "df_features['meanvisdow_mul_rnkarea'] = df_features.v_cntair_store_idday_of_week * df_features.store_rank_area_dow\n",
    "df_features['meanvisdow_mul_rnkpref'] = df_features.v_cntair_store_idday_of_week * df_features.store_rank_pref_dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:24:15.747184Z",
     "start_time": "2018-09-24T05:24:05.266227Z"
    }
   },
   "outputs": [],
   "source": [
    "# some of the features in the test set have na...work out the mean from the train set to add down below\n",
    "any_nulls = df_features.isna().any()\n",
    "any_nulls = list(any_nulls[any_nulls==True].index)\n",
    "mean_nulls = df_features[df_features.id.notna()].loc[:,any_nulls].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:24:16.590694Z",
     "start_time": "2018-09-24T05:24:15.748183Z"
    }
   },
   "outputs": [],
   "source": [
    "# exclude dummies for:\n",
    "# - air_store_id as mean per store is unique per store anyway.\n",
    "# - season as information is included in the month\n",
    "# - area_name as info included in lat/long\n",
    "# - genre2 as info in air_genre_name\n",
    "\n",
    "# df_features_dum = pd.get_dummies(df_features[(df_features.visit_date)>=(datetime.date(2016,7,1))],\n",
    "#                                  columns=['air_genre_name','area_pref'],\n",
    "#                                  drop_first=True)\n",
    "# drop_cols = ['id','visit_date','visitors','air_store_id','air_area_name',\n",
    "#              'visit_season','air_genre_2','day_of_week','visit_month','golden_week'\n",
    "\n",
    "\n",
    "df_features_dum = df_features[(df_features.visit_date) >= (date_incl)].copy()\n",
    "drop_cols = ['id','visit_date','visitors','air_store_id','air_area_name','air_genre_name','area_pref',\n",
    "             'visit_season','air_genre_2','day_of_week','visit_month','golden_week']\n",
    "\n",
    "df_train = df_features_dum[df_features_dum.id.isna()].sort_values(by='visit_date_int').copy()\n",
    "y=np.log1p(df_train['visitors'].values)\n",
    "df_train.drop(columns=drop_cols,inplace=True)\n",
    "\n",
    "df_test = df_features_dum[df_features_dum.id.notna()].sort_values(by='visit_date_int').copy()\n",
    "df_test.drop(columns=drop_cols,inplace=True)\n",
    "\n",
    "df_test.fillna(-1,inplace=True)\n",
    "df_train.fillna(-1,inplace=True)\n",
    "\n",
    "#y=np.log1p(df_air_visit_incl['visitors'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:26:28.721498Z",
     "start_time": "2018-09-24T05:24:16.592693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.132870537505463, 'max_bin': 316, 'min_child_samples': 54, 'min_child_weight': 6, 'n_estimators': 99, 'num_leaves': 69}\n",
      "RMSE LGBMRegressor:  0.4486522607431908\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "tscv = model_selection.KFold(n_splits=splits)\n",
    "tscv_cv = tscv.split(df_train)\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(10, 100),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"num_leaves\": st.randint(31, 100),\n",
    "    \"max_bin\": st.randint(200, 400),\n",
    "    \"min_child_weight\": st.randint(1, 10),\n",
    "    \"min_child_samples\": st.randint(1, 100),\n",
    "}   \n",
    "lgbm = lgb.LGBMRegressor()\n",
    "lgbmrscv = model_selection.RandomizedSearchCV(lgbm, params, n_iter=10,cv=tscv_cv)  \n",
    "lgbmrscv.fit(df_train, y)\n",
    "print(lgbmrscv.best_params_)\n",
    "print('RMSE LGBMRegressor: ', RMSLE(y, lgbmrscv.predict(df_train)))\n",
    "df_test_out = df_test.copy()\n",
    "df_test_out['visitors'] = lgbmrscv.predict(df_test)\n",
    "df_test_out['visitors'] = np.expm1(df_test_out['visitors']).clip(lower=1.)\n",
    "df_test_out = df_test_out.sort_index()\n",
    "df_sample['visitors'] = df_test_out['visitors'].values\n",
    "lgbmrscv_out = df_sample[['id','visitors']].copy()\n",
    "lgbmrscv_out.to_csv('lgbmrscv_out_'+datetime.datetime.now().strftime('%Y%m%d%I%M')+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T05:26:45.220984Z",
     "start_time": "2018-09-24T05:26:28.723497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "RMSE LightGBM best iteration, fold  0 :  55\n",
      "RMSE LightGBM, fold  0 :  0.47456850675712026\n",
      "\n",
      "Fold  1\n",
      "RMSE LightGBM best iteration, fold  1 :  70\n",
      "RMSE LightGBM, fold  1 :  0.47042579691806985\n",
      "\n",
      "Fold  2\n",
      "RMSE LightGBM best iteration, fold  2 :  64\n",
      "RMSE LightGBM, fold  2 :  0.4832980196150528\n",
      "\n",
      "Fold  3\n",
      "RMSE LightGBM best iteration, fold  3 :  39\n",
      "RMSE LightGBM, fold  3 :  0.4635961685377659\n"
     ]
    }
   ],
   "source": [
    "# LightGBM with Time Series CV\n",
    "tscv = model_selection.KFold(n_splits=splits)\n",
    "tscv_cv = tscv.split(df_train)\n",
    "y_test_pred = 0\n",
    "lgbmtscv = lgbmrscv.best_estimator_\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(df_train)):\n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y[train_index].copy(), y[test_index]\n",
    "    X_train, X_valid = df_train.iloc[train_index, :].copy(), df_train.iloc[test_index, :].copy()\n",
    "    print(\"\\nFold \", i)\n",
    "\n",
    "    evals=[(X_valid,y_valid)]\n",
    "    lgbmtscv.fit(X_train, y_train,eval_set=evals,early_stopping_rounds=5,verbose=False,eval_metric='l2_root')\n",
    "    pred = lgbmtscv.predict(X_valid,num_iteration=lgbmtscv.best_iteration_)\n",
    "    print('RMSE LightGBM best iteration, fold ', i, ': ', lgbmtscv.best_iteration_)\n",
    "    print('RMSE LightGBM, fold ', i, ': ', RMSLE(y_valid, pred))\n",
    "    # Accumulate test set predictions\n",
    "\n",
    "    pred = lgbmtscv.predict(df_test,num_iteration=lgbmtscv.best_iteration_)\n",
    "    y_test_pred += pred\n",
    "\n",
    "y_test_pred/=splits\n",
    "df_test_out = df_test.copy()\n",
    "df_test_out['visitors'] = y_test_pred\n",
    "df_test_out['visitors'] = np.expm1(df_test_out['visitors']).clip(lower=1.)\n",
    "df_test_out = df_test_out.sort_index()\n",
    "df_sample['visitors'] = df_test_out['visitors'].values\n",
    "lgbmtscv_out = df_sample[['id','visitors']].copy()\n",
    "lgbmtscv_out.to_csv('lgbmtscv_out_'+datetime.datetime.now().strftime('%Y%m%d%I%M')+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:03:52.469639Z",
     "start_time": "2018-09-24T05:26:45.222983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9531025392538498, 'gamma': 8.387351870014246, 'learning_rate': 0.394083536041345, 'max_depth': 38, 'min_child_weight': 156.89985691533957, 'n_estimators': 16, 'reg_alpha': 10.549561598021711, 'subsample': 0.9652230734993309}\n",
      "RMSE XGBRegressor:  0.46837784025257445\n"
     ]
    }
   ],
   "source": [
    "# XGBRegressor\n",
    "tscv = model_selection.KFold(n_splits=splits)\n",
    "tscv_cv = tscv.split(df_train)\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 40),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'reg_alpha': from_zero_positive,\n",
    "    \"min_child_weight\": from_zero_positive,\n",
    "}\n",
    "\n",
    "xgbr = xgb.XGBRegressor()\n",
    "xgbrscv = model_selection.RandomizedSearchCV(\n",
    "    xgbr, params, n_iter=10, cv=tscv_cv)\n",
    "xgbrscv.fit(df_train, y)\n",
    "print(xgbrscv.best_params_)\n",
    "print('RMSE XGBRegressor: ',\n",
    "      RMSLE(y, xgbrscv.best_estimator_.predict(df_train)))\n",
    "df_test_out = df_test.copy()\n",
    "df_test_out['visitors'] = xgbrscv.best_estimator_.predict(df_test)\n",
    "df_test_out['visitors'] = np.expm1(df_test_out['visitors']).clip(lower=1.)\n",
    "df_test_out = df_test_out.sort_index()\n",
    "df_sample['visitors'] = df_test_out['visitors'].values\n",
    "xgbrscv_out = df_sample[['id', 'visitors']].copy()\n",
    "xgbrscv_out.to_csv(\n",
    "    'xgbrscv_out_' + datetime.datetime.now().strftime('%Y%m%d%I%M') + '.csv',\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:08:01.812268Z",
     "start_time": "2018-09-24T06:03:52.471628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "RMSE XGBRegressor, fold  0 :  0.48211208816076656\n",
      "RMSE XGBRegressor best iteration, fold  0 :  15\n",
      "\n",
      "Fold  1\n",
      "RMSE XGBRegressor, fold  1 :  0.4774096833843761\n",
      "RMSE XGBRegressor best iteration, fold  1 :  15\n",
      "\n",
      "Fold  2\n",
      "RMSE XGBRegressor, fold  2 :  0.4910563861068349\n",
      "RMSE XGBRegressor best iteration, fold  2 :  15\n",
      "\n",
      "Fold  3\n",
      "RMSE XGBRegressor, fold  3 :  0.46774997966283244\n",
      "RMSE XGBRegressor best iteration, fold  3 :  15\n"
     ]
    }
   ],
   "source": [
    "# XGBRegressor with Time Series CV\n",
    "tscv = model_selection.KFold(n_splits=splits)\n",
    "tscv_cv = tscv.split(df_train)\n",
    "y_test_pred = 0\n",
    "xgbtscv = xgbrscv.best_estimator_\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(df_train)):\n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y[train_index].copy(), y[test_index]\n",
    "    X_train, X_valid = df_train.iloc[train_index, :].copy(), df_train.iloc[test_index, :].copy()\n",
    "    print(\"\\nFold \", i)\n",
    "\n",
    "    evals = [(X_valid, y_valid)]\n",
    "    xgbtscv.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=evals,\n",
    "        early_stopping_rounds=5,\n",
    "        verbose=False,\n",
    "        eval_metric='rmse')\n",
    "    pred = xgbtscv.predict(X_valid)\n",
    "    print('RMSE XGBRegressor, fold ', i, ': ', RMSLE(y_valid, pred))\n",
    "    print('RMSE XGBRegressor best iteration, fold ', i, ': ',\n",
    "          xgbtscv.best_iteration)\n",
    "    # Accumulate test set predictions\n",
    "\n",
    "    pred = xgbtscv.predict(df_test)\n",
    "    y_test_pred += pred\n",
    "\n",
    "y_test_pred /= splits\n",
    "df_test_out = df_test.copy()\n",
    "df_test_out['visitors'] = y_test_pred\n",
    "df_test_out['visitors'] = np.expm1(df_test_out['visitors']).clip(lower=1.)\n",
    "df_test_out = df_test_out.sort_index()\n",
    "df_sample['visitors'] = df_test_out['visitors'].values\n",
    "xgbtscv_out = df_sample[['id', 'visitors']].copy()\n",
    "xgbtscv_out.to_csv(\n",
    "    'xgbtscv_out_' + datetime.datetime.now().strftime('%Y%m%d%I%M') + '.csv',\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:08:02.079104Z",
     "start_time": "2018-09-24T06:08:01.813259Z"
    }
   },
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub=xgbtscv_out.merge(xgbrscv_out, on='id',suffixes=('_xgbtscv','_xgbrscv'))\\\n",
    "               .merge(lgbmtscv_out,on='id')\\\n",
    "               .merge(lgbmrscv_out,on='id',suffixes=('lgbmtscv','lgbmrscv'))\n",
    "df_sample['visitors'] = sub.mean(axis=1)\n",
    "mean_out = df_sample[['id','visitors']].copy()\n",
    "mean_out.to_csv('mean_out_'+datetime.datetime.now().strftime('%Y%m%d%I%M')+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:08:02.267011Z",
     "start_time": "2018-09-24T06:08:02.081105Z"
    }
   },
   "outputs": [],
   "source": [
    "sub1 = pd.DataFrame()\n",
    "sub1 = xgbtscv_out.merge(xgbrscv_out, on='id', suffixes=('xgbtscv', 'xgbrscv'))\n",
    "df_sample['visitors'] = sub1.mean(axis=1)\n",
    "mean_out1 = df_sample[['id', 'visitors']].copy()\n",
    "mean_out1.to_csv(\n",
    "    'mean_xgb_out_' + datetime.datetime.now().strftime('%Y%m%d%I%M') + '.csv',\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:08:02.603804Z",
     "start_time": "2018-09-24T06:08:02.268997Z"
    }
   },
   "outputs": [],
   "source": [
    "sub2 = pd.DataFrame()\n",
    "sub2 = lgbmtscv_out.merge(\n",
    "    lgbmrscv_out, on='id', suffixes=('lgbmtscv', 'lgbmrscv'))\n",
    "df_sample['visitors'] = sub2.mean(axis=1)\n",
    "mean_out2 = df_sample[['id', 'visitors']].copy()\n",
    "mean_out2.to_csv(\n",
    "    'mean_lgbm_out_' + datetime.datetime.now().strftime('%Y%m%d%I%M') + '.csv',\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T06:08:02.908636Z",
     "start_time": "2018-09-24T06:08:02.608801Z"
    }
   },
   "outputs": [],
   "source": [
    "sub3 = pd.DataFrame()\n",
    "sub3 = xgbtscv_out.merge(\n",
    "    lgbmtscv_out, on='id', suffixes=('xgbtscv', 'lgbmtscv'))\n",
    "df_sample['visitors'] = sub3.mean(axis=1)\n",
    "mean_out3 = df_sample[['id', 'visitors']].copy()\n",
    "mean_out3.to_csv(\n",
    "    'mean_tscv_out_' + datetime.datetime.now().strftime('%Y%m%d%I%M') + '.csv',\n",
    "    index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
